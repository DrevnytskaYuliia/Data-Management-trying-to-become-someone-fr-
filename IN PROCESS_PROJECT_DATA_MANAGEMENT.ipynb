{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrevnytskaYuliia/Data-Management-trying-to-become-someone-fr-/blob/main/B_PROJECT_DATA_MANAGEMENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Motivation and Introduction**\n",
        "\n",
        "The retail industry has changed due to the development of eCommerce platforms, which have left behind extensive digital records of customer behaviour. Every click, view, and purchase generates useful data that businesses can use to get better understanding of their clients, enhance user experience, and boost sales. However, there are analytical and technical difficulties in analysing such large amounts of behavioural data.\n",
        "\n",
        "The user interaction data used in this project was gathered over a seven-month period from a large multi-category online store, recording over 285 million events such as product views, cart additions, and purchases. Our goal is to extract insights from this behavioural data so that we can make better decisions in areas like revenue forecasting, personalised marketing, and customer segmentation.\n",
        "\n",
        "We use a mix of classification, regression, and clustering methods to investigate the possibilities of the data. These techniques allow us to predict the likelihood of transformation, identify different types of customers, and estimate future customer value."
      ],
      "metadata": {
        "id": "1a6K95-JCS2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset description**\n",
        "\n",
        "The dataset used in this project is titled **“eCommerce behavior data from multi category store”**, publicly available on Kaggle.\n",
        "It was collected as part of the Open CDP (Customer Data Platform) project.\n",
        "\n",
        "It consists of approximately 67.5 million rows and captures user behavior events over a 7-month period (October 2019 to April 2020). Each row represents an interaction between a user and a product on a multi-category eCommerce platform.\n",
        "\n",
        "**Total values:** 67501979\n",
        "\n",
        "Main features of each variable in the dataset:\n",
        "\n",
        "\n",
        "*   **event_time:** Records the exact timestamp of the user interaction with the platform (in UTC format).\n",
        "*   **event_type:** Indicates the type of user action. Possible values include:\n",
        "\n",
        "**view** – the user viewed a product\n",
        "\n",
        "**cart** – the user added a product to cart\n",
        "\n",
        "**remove_from_cart** – the user removed a product from cart\n",
        "\n",
        "**purchase** – the user completed a purchase\n",
        "\n",
        "*   **product_id:** A unique identifier for the product.\n",
        "*   **category_id:** Numeric ID representing the product category.\n",
        "*   **category_code:** Hierarchical string that describes the product category (e.g., electronics.smartphone, appliances.kitchen.)\n",
        "*   **brand:** Name of the product brand.\n",
        "*   **price:** Price of the product at the time of the interaction.\n",
        "*   **user_id:** Unique anonymous identifier for the user.\n",
        "*   **user_session:** Session ID used to group actions by browsing sessions."
      ],
      "metadata": {
        "id": "eaacR207F-Ow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Research questions tackled**\n",
        "\n",
        "**1. Clustering**\n",
        "\n",
        "How can we group users based on their shopping behavior (e.g., frequency of views, cart additions, and purchases), and what distinct customer personas emerge from these clusters?\n",
        "\n",
        "1.1 Can we identify distinct shopper personas (ex. window shoppers, cart abandoners, impulse buyers etc.)\n",
        "\n",
        "1.2 How do these personas differ by product category preferences or average price points?\n",
        "\n",
        "1.3 Are there differences in when and how often these groups shop?\n",
        "\n",
        "1.4 Do patterns like repeat visits, short vs. long sessions, or quick purchase decisions help distinguish these clusters?\n",
        "\n",
        "**2. Regression**\n",
        "\n",
        "Can we predict the total revenue generated by a user based on their product browsing and cart behavior?\n",
        "\n",
        "2.1  How does the number of product views and cart additions relate to the purchase amount?\n",
        "\n",
        "2.2 Does the average price of viewed or carted products influence the final amount spent?\n",
        "\n",
        "2.3 Do users who interact with multiple product categories tend to spend more?\n",
        "\n",
        "2.4 Does recency or frequency of interaction affect total spending?\n",
        "\n",
        "**3. Classification**\n",
        "\n",
        "Can we classify whether a user will make a purchase within the next 7 days based on their recent browsing behavior?\n",
        "\n",
        "3.1  Which behavioral signals are most predictive of an upcoming purchase?\n",
        "\n",
        "3.2  Does cart behavior (e.g., added but not purchased) increase the likelihood of a purchase soon?\n",
        "\n",
        "3.3 How well can we predict the likelihood of a purchase in the next 7 days?\n",
        "\n",
        "3.4 Can we detect patterns in user behavior that help us intervene earlier?"
      ],
      "metadata": {
        "id": "3DLuRq6tLw9t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**References**\n",
        "**TO FIND**"
      ],
      "metadata": {
        "id": "uOUlZFq_ZoAi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import**"
      ],
      "metadata": {
        "id": "yIZF5vCYZeE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder"
      ],
      "metadata": {
        "id": "4F3Kguy5Zf9e"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "xWmcSp52aGZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca779225-b5bb-41fb-e41d-b23c09a65c12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.6.15)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.4.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STEP 1: Load Data**\n"
      ],
      "metadata": {
        "id": "powl95ZEc833"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# 2. Set the path to a specific CSV file from the dataset\n",
        "file_path = \"2019-Oct.csv\"\n",
        "\n",
        "# 3. Load into a DataFrame\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"mkechinov/ecommerce-behavior-data-from-multi-category-store\",\n",
        "    file_path\n",
        ")\n",
        "\n",
        "# 4. Preview\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPDw1lWbeVW_",
        "outputId": "895072c2-6e4d-4774-e9e1-936332e34437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3-1741159564.py:8: DeprecationWarning: load_dataset is deprecated and will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have decided to go with sample of the data, understanding our large dataset limitations and also I added the index restart\n",
        "\n",
        "df_sampled = (df.groupby('event_type', group_keys=False).apply(lambda x: x.sample(frac=0.1, random_state=42)).reset_index(drop=True))"
      ],
      "metadata": {
        "id": "C75KcA_qApmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_sampled.head())"
      ],
      "metadata": {
        "id": "Z53tJjbNES4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets look if sampling is sucessfull. It is, we have got 10 percent, that follows the shape of original data\n",
        "\n",
        "print(\"Original shape:\", df.shape)\n",
        "print(\"Sampled shape:\", df_sampled.shape)\n",
        "\n",
        "print(\"Original nulls:\\n\", df.isnull().sum())\n",
        "print(\"Sampled nulls:\\n\", df_sampled.isnull().sum())"
      ],
      "metadata": {
        "id": "vU4q3S6oL8hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 2: Prepare and investigate data"
      ],
      "metadata": {
        "id": "h6woQDyvkBol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_sampled.info()"
      ],
      "metadata": {
        "id": "wgi3LG9aBFpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# then we need to change event_time to processable format\n",
        "\n",
        "df_sampled['event_time'] = pd.to_datetime(df_sampled['event_time'], errors='coerce')"
      ],
      "metadata": {
        "id": "fhUkyE2ZF9l1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#looking at data - sad sad\n",
        "df_sampled.isnull().sum()"
      ],
      "metadata": {
        "id": "fzeE7UdBkM80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As we have a lot of missing vakues for category_code and brand, we have decided to fill them\n",
        "\n",
        "df_sampled['brand'] = df_sampled['brand'].fillna('unknown')\n",
        "df_sampled['category_code'] = df_sampled['category_code'].fillna('unknown')"
      ],
      "metadata": {
        "id": "8ao0Nrq5nsXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sucessfully filled\n",
        "\n",
        "df_sampled.isnull().sum()"
      ],
      "metadata": {
        "id": "4zrAL3i5oQh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#looking for the duplicates\n",
        "\n",
        "df_sampled.duplicated().sum()"
      ],
      "metadata": {
        "id": "CgyXc-R1oQ9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#it showed us exact duplicates, so it would be safe to delete those\n",
        "\n",
        "df_sampled = df_sampled.drop_duplicates()"
      ],
      "metadata": {
        "id": "wKyU4AACOJqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Also lets look at the prices and see if there is something unreasinable, so 0 or with minus sign\n",
        "\n",
        "bad_prices = df_sampled[df_sampled['price'] <= 0]\n",
        "print(\"Rows with price <= 0:\", len(bad_prices))\n",
        "\n",
        "bad_prices.head()"
      ],
      "metadata": {
        "id": "iIQMu0h3OX-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#so we are dropping price that is 0 or smaller, but inly for cart and purchase. because view can help us with behavioural analysis still and does no harm for predicting revenue or values\n",
        "\n",
        "df_sampled = df_sampled[~((df_sampled['price'] <= 0) & (df_sampled['event_type'].isin(['cart', 'purchase'])))]\n"
      ],
      "metadata": {
        "id": "F5F8VYm2STtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#also checked if there are unrealistically big prices\n",
        "\n",
        "df_sampled.sort_values(by='price', ascending=False).head()"
      ],
      "metadata": {
        "id": "l0mccGh1RPkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#also we need to see if some of the users are suspicious, so looked at the\n",
        "\n",
        "df_sampled['user_id'].value_counts().head(20)"
      ],
      "metadata": {
        "id": "UI2tLkSGTs-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#looked for suspicious activity, but bro  is probably a window shoppper\n",
        "top_user = df_sampled[df_sampled['user_id'] == 512475445]\n",
        "top_user['event_type'].value_counts()"
      ],
      "metadata": {
        "id": "MrWpZ8noUBlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation (User DF)"
      ],
      "metadata": {
        "id": "drvv4ib7vWSI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "features Extract additional features чи це будні дні чи вихідні\n",
        "Можна зробити лейбли\n"
      ],
      "metadata": {
        "id": "jVuLrWSJTPQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#adding tags to see how many times each user vieweed, put something into cart or purchased by adding aditional columns\n",
        "\n",
        "df_sampled['view'] = (df_sampled['event_type'] == 'view').astype(int)\n",
        "df_sampled['cart'] = (df_sampled['event_type'] == 'cart').astype(int)\n",
        "df_sampled['purchase'] = (df_sampled['event_type'] == 'purchase').astype(int)"
      ],
      "metadata": {
        "id": "jgmMXgPyx-2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doing separate columns for hours\n",
        "\n",
        "df_sampled['hour_of_day'] = df_sampled['event_time'].dt.hour\n",
        "df_sampled['weekday_name'] = df_sampled['event_time'].dt.day_name()\n",
        "\n",
        "# Tag weekends using the weekday name\n",
        "df_sampled['is_weekend'] = df_sampled['weekday_name'].isin(['Saturday', 'Sunday'])"
      ],
      "metadata": {
        "id": "1QWfsbVg-5Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sampled.head()"
      ],
      "metadata": {
        "id": "lNtIEz_a_CKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#then decided to concentrate on users and do a new df to define their actions grouping by user id. Also aggregate basic statistics per user\n",
        "\n",
        "views = df_sampled[df_sampled['view'] == 1]\n",
        "carts = df_sampled[df_sampled['cart'] == 1]\n",
        "purchases = df_sampled[df_sampled['purchase'] == 1] #price-based stats filering\n",
        "\n",
        "avg_price_viewed = views.groupby('user_id')['price'].mean().reset_index(name='avg_price_viewed') #separation by groups\n",
        "avg_price_carted = carts.groupby('user_id')['price'].mean().reset_index(name='avg_price_carted')\n",
        "total_spent = purchases.groupby('user_id')['price'].sum().reset_index(name='total_spent')\n",
        "\n",
        "user_df = df_sampled.groupby('user_id').agg(\n",
        "    total_views=('view', 'sum'),\n",
        "    total_cart_additions=('cart', 'sum'),\n",
        "    total_purchases=('purchase', 'sum'),\n",
        "    num_categories=('category_code', pd.Series.nunique),\n",
        "    num_products_viewed=('product_id', pd.Series.nunique),\n",
        "    first_action=('event_time', 'min'),\n",
        "    last_action=('event_time', 'max'),\n",
        "    num_events=('event_time', 'count')\n",
        ").reset_index() # Calculate base user metrics\n",
        "\n",
        "# Merge it all\n",
        "user_df = user_df.merge(avg_price_viewed, on='user_id', how='left')\n",
        "user_df = user_df.merge(avg_price_carted, on='user_id', how='left')\n",
        "user_df = user_df.merge(total_spent, on='user_id', how='left')"
      ],
      "metadata": {
        "id": "hBBv2sY9ybeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#also fill avg_price_carted and total_spent with 0\n",
        "\n",
        "user_df['avg_price_carted'] = user_df['avg_price_carted'].fillna(0)\n",
        "user_df['total_spent'] = user_df['total_spent'].fillna(0)"
      ],
      "metadata": {
        "id": "dV9V2wah6IjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_df['activity_days'] = (user_df['last_action'] - user_df['first_action']).dt.days + 1 #number of active days (added 0, to add the day of a start)\n",
        "\n",
        "user_df['event_frequency'] = user_df['num_events'] / user_df['activity_days'] #event frequency (number per day)\n",
        "\n",
        "user_df['cart_to_view_ratio'] = user_df['total_cart_additions'] / (user_df['total_views'] + 1e-5)\n",
        "\n",
        "user_df['purchase_to_cart_ratio'] = user_df['total_purchases'] / (user_df['total_cart_additions'] + 1e-5)\n",
        "\n",
        "user_df['purchase_to_view_ratio'] = user_df['total_purchases'] / (user_df['total_views'] + 1e-5)\n",
        "\n",
        "user_df['cart_to_purchase_ratio'] = user_df['total_cart_additions'] / (user_df['total_purchases'] + 1e-5)\n",
        "\n",
        "\n",
        "user_df['cart_to_purchase_ratio'] = user_df['cart_to_purchase_ratio'].fillna(0)\n",
        "user_df['cart_to_view_ratio'] = user_df['cart_to_view_ratio'].fillna(0)\n",
        "user_df['purchase_to_view_ratio'] = user_df['purchase_to_view_ratio'].fillna(0)\n",
        "user_df['purchase_to_cart_ratio'] = user_df['purchase_to_cart_ratio'].fillna(0)"
      ],
      "metadata": {
        "id": "zdfX39sQ6zFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# % of events on weekends\n",
        "weekend_share = df_sampled.groupby('user_id')['is_weekend'].mean().reset_index(name='weekend_activity_ratio')\n",
        "\n",
        "# Most active hour of the day (mode)\n",
        "active_hour = df_sampled.groupby('user_id')['hour_of_day'].agg(lambda x: x.mode().iloc[0]).reset_index(name='most_active_hour')\n"
      ],
      "metadata": {
        "id": "FXCiGWoIAijk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Also wanna sort it to improve readability\n",
        "\n",
        "user_df = user_df[\n",
        "    [    'user_id',\n",
        "\n",
        "        # Activity\n",
        "        'total_views', 'total_cart_additions', 'total_purchases',\n",
        "        'num_events', 'activity_days', 'active_hour' 'event_frequency', 'weekend_share'\n",
        "\n",
        "        # Behavior\n",
        "        'cart_to_view_ratio', 'cart_to_purchase_ratio', 'purchase_to_view_ratio',\n",
        "\n",
        "        # Monetary\n",
        "        'avg_price_viewed', 'avg_price_carted', 'total_spent',\n",
        "\n",
        "        # Diversity of engagement\n",
        "        'num_categories', 'num_products_viewed',\n",
        "\n",
        "        # Timestamps\n",
        "        'first_action', 'last_action' ]]"
      ],
      "metadata": {
        "id": "SOmLcG9J8gst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_df.head()"
      ],
      "metadata": {
        "id": "BS7Auunw1dOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 3: Clustering"
      ],
      "metadata": {
        "id": "Yug7bwxsq6W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 4: Regression modeling"
      ],
      "metadata": {
        "id": "pB9DiWy3rPTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEP 5: Classification"
      ],
      "metadata": {
        "id": "R0tzUIHurSUp"
      }
    }
  ]
}
